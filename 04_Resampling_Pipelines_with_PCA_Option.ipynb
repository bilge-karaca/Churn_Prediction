{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "861fa039",
   "metadata": {},
   "source": [
    "# Resampling (SMOTE, Random Oversampling, Random Undersampling) on Network-Features-Enhanced-Dataset.\n",
    "With / without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27230a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle \n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, precision_recall_curve\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, roc_auc_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, average_precision_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "from imblearn.pipeline import Pipeline as pipe_imb\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "\n",
    "def f1_macro(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b910b51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('OM_D3_results_table', 'rb')\n",
    "baseline_nx_table = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "\n",
    "f = open('OM_D3_Dataset_2_nx-features-added-brand_new', 'rb')\n",
    "data_nx = pickle.load(f)\n",
    "f.close()\n",
    "print(data_nx.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99065222",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facb40ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, precision_recall_curve\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, roc_auc_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e19b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame to store the results\n",
    "def print_results(headline, true_value, pred, probs):\n",
    "    scores=[]\n",
    "    CM = confusion_matrix(true_value, pred)\n",
    "    scores.append(headline)\n",
    "    scores.append(accuracy_score(true_value, pred))      #accuracy\n",
    "    scores.append(int(CM[1,1]))                          #TP\n",
    "    scores.append(int(CM[0,1]))                          #FP\n",
    "    scores.append(int(CM[0][0]))                         #TN\n",
    "    scores.append(int(CM[1][0]))                         #FN\n",
    "    scores.append(precision_score(true_value, pred))     #precision\n",
    "    scores.append(recall_score(true_value, pred))        #recall\n",
    "    scores.append(roc_auc_score(true_value, probs))      #roc_auc\n",
    "    p, r, _ = precision_recall_curve(true_value, probs) \n",
    "    scores.append(auc(r,p))                              #pr_auc\n",
    "    scores.append(f1_score(true_value, pred, average=\"macro\"))            #f1-score\n",
    "    return scores\n",
    "\n",
    "score_names = ['method','accuracy','TP','FP','TN','FN','precision','recall','roc_auc','pr_auc','f1']\n",
    "dfAcc = pd.DataFrame(data=np.zeros(shape=(0,11)), columns = score_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ccd088",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= data_nx.drop([\"CustomerID\",\"label\"],axis=1)\n",
    "y= data_nx[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b36cef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars= ['EmailContactable','City', 'last_coupon_type_used','DeviceType']\n",
    "X.drop(cat_vars,axis=1,inplace=True)\n",
    "num_vars=list(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a3ff5f",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251ec69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "num_vars = list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db853c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"pipe_cat = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"one_hot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\"\"\"\n",
    "pipe_num = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    #(\"categorical_vars\", pipe_cat, cat_vars),\n",
    "    (\"numeric_vars\", pipe_num, num_vars),\n",
    "    \n",
    "], remainder=\"passthrough\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b9005e",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef7d934",
   "metadata": {},
   "outputs": [],
   "source": [
    "ovsmp_pipe = pipe_imb([('ct'        , ct),\n",
    "                 #     ('dim_red'   , PCA()),\n",
    "                       ('sampler'   , RandomOverSampler(random_state=42,\n",
    "                                                       sampling_strategy = 0.6)),\n",
    "                       ('classifier', LogisticRegression(random_state=42, max_iter=100000))\n",
    "                          ]\n",
    "                   )\n",
    "\n",
    "params = [\n",
    "\n",
    "\n",
    "            {'classifier__C'      :[0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], \n",
    "           'classifier__penalty': ['l1'],\n",
    "           'classifier__solver' : ['liblinear', 'saga'],\n",
    "        #     'dim_red__n_components': [8, 10, 13,15],\n",
    "            'sampler__sampling_strategy': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]},\n",
    "\n",
    "\n",
    "          {'classifier__C'      : [0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], \n",
    "           'classifier__penalty': ['l2'], \n",
    "           'classifier__solver' : ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "     #     'dim_red__n_components': [8, 10, 13,15],\n",
    "            'sampler__sampling_strategy': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "          }]\n",
    "\n",
    "         \n",
    "\n",
    "# train/validation with the same ratio of classes\n",
    "kfold = StratifiedKFold(n_splits = 4, random_state = 42, shuffle=True) \n",
    "\n",
    "grid = GridSearchCV(ovsmp_pipe, \n",
    "                    param_grid = params, \n",
    "                    cv = kfold, \n",
    "                    scoring = 'f1_macro', \n",
    "                    verbose = 1,\n",
    "                    n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89dd4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run the grid search \n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_estimator_,'\\n')\n",
    "print('Best parameters  :', grid.best_params_)\n",
    "print('\\nTraining F1_macro:', grid.score(X_train, y_train))\n",
    "print('Test F1_macro :', grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76999c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = grid.predict_proba(X_test)[:,1]\n",
    "scores = print_results('D4_LoR_oversmp', y_test, grid.predict(X_test), pred_probs)\n",
    "dftmp = pd.DataFrame([scores], columns=score_names)\n",
    "dfAcc = pd.concat([dfAcc, dftmp], ignore_index=True)\n",
    "dfAcc[['TP','FP', 'TN', 'FN']] = dfAcc[['TP','FP', 'TN', 'FN']].astype(int)\n",
    "dfAcc.style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe74cfb",
   "metadata": {},
   "source": [
    "# D3_XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da33e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_macro(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a705a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "ovsmp_pipe = pipe_imb([('ct'        , ct),\n",
    "                 #     ('dim_red'   , PCA()),\n",
    "                       ('sampler'   , RandomOverSampler(random_state=42,\n",
    "                                                       sampling_strategy=0.5)),\n",
    "                       ('classifier', XGBClassifier(objective='binary:logistic', \n",
    "                                                    eval_metric = f1_macro,\n",
    "                                                    n_estimators=1000, \n",
    "                                                    eta=0.01, # default 0.3\n",
    "                                                    max_depth=6, \n",
    "                                                    subsample=0.8, \n",
    "                                                    min_child_weight=25, \n",
    "                                                    gamma=1, \n",
    "                                                    reg_lambda=1, \n",
    "                                                    alpha=1, \n",
    "                                                    colsample_bytree=0.9, \n",
    "                                                    #colsample_bylevel=0.5,\n",
    "                                                   # scale_pos_weight = 0.35\n",
    "                                                   )\n",
    "                                                   )\n",
    "                            ]\n",
    "                   )\n",
    "\n",
    "\n",
    "\n",
    "params = [{\n",
    "            'sampler__sampling_strategy': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "                #     'dim_red__n_components': [8, 10, 13,15],\n",
    "          #  'classifier__n_estimators':[750,1000,1500],\n",
    "          # 'classifier__eta': [0.01,0.001,0.0001]\n",
    "          #  'classifier__max_depth':[1],\n",
    "          # 'classifier__min_child_weight': [200],\n",
    "        #   'classifier__colsample_bytree':[0.5], #,0.6,0.7,0.8,0.9],\n",
    "         #  'classifier__subsample' : [0.7],\n",
    "         #  'classifier__alpha':[5], #  defult 0. Increasing this value will make model more conservative.\n",
    "          #  'classifier__gamma':[5], #  defult 0. Increasing this value will make model more conservative.\n",
    "           # 'classifier__reg_lambda':[5], #  def=1 .Increasing this value will make model more conservative.\n",
    "         #   'classifier__scale_pos_weight' : [1]\n",
    "}\n",
    "         ]\n",
    "\n",
    "\n",
    "\n",
    "# train/validation with the same ratio of classes\n",
    "kfold = StratifiedKFold(n_splits = 4, random_state = 42, shuffle=True) \n",
    "\n",
    "grid = GridSearchCV(ovsmp_pipe, \n",
    "                    param_grid = params, \n",
    "                    cv = kfold, \n",
    "                    scoring = 'f1_macro', \n",
    "                    verbose = 1,\n",
    "                    n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bc0beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run the grid search \n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_estimator_,'\\n')\n",
    "print('Best parameters  :', grid.best_params_)\n",
    "print('\\nTraining F1 score:', grid.score(X_train, y_train))\n",
    "print(\"Test F1 score:\", grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2d7b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = grid.predict_proba(X_test)[:,1]\n",
    "scores = print_results('D4_XGB_oversmp', y_test, grid.predict(X_test), pred_probs)\n",
    "dftmp = pd.DataFrame([scores], columns=score_names)\n",
    "dfAcc = pd.concat([dfAcc, dftmp], ignore_index=True)\n",
    "dfAcc[['TP','FP', 'TN', 'FN']] = dfAcc[['TP','FP', 'TN', 'FN']].astype(int)\n",
    "dfAcc.style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25456618",
   "metadata": {},
   "source": [
    "# LIGHTGBM / OVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbe73a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIGHTGBM\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "ovsmp_pipe = pipe_imb([('ct'        , ct),            \n",
    "                        #     ('dim_red'   , PCA()),\n",
    "                       ('sampler'   , RandomOverSampler(random_state=42,\n",
    "                                                       sampling_strategy=0.5)),\n",
    "                       ('LGBM',   lgb.LGBMClassifier(objective=\"binary\",\n",
    "                                                   #  class_weight=\"balanced\",                                                   \n",
    "                                                     n_estimators=1000, \n",
    "                                                     learning_rate=0.01,\n",
    "                                                     min_child_weight=25, \n",
    "                                                      max_depth=6, \n",
    "                                                     num_leaves=25, \n",
    "                                                     min_child_samples=25,                                                      \n",
    "                                                     reg_alpha=1, \n",
    "                                                     reg_lambda=1,\n",
    "                                                 #    subsample_freq=0, \n",
    "                                                     colsample_bytree=0.8, \n",
    "                                                     subsample=0.7,\n",
    "                                                     min_split_gain = 25,\n",
    "                                                      min_data_in_leaf = 25,\n",
    "                                                     random_state=42))\n",
    "                          ]\n",
    "                   )\n",
    "\n",
    "\n",
    "param_grid = [{\n",
    "                'sampler__sampling_strategy': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "                #     'dim_red__n_components': [8, 10, 13,15],\n",
    "             #        'LGBM__n_estimators': [750,1000,1500], \n",
    "            #     'LGBM__learning_rate' : [0.0001,0.001,0.01],\n",
    "                  'LGBM__min_child_weight': [60], #\n",
    "                  'LGBM__max_depth' : [2],          #\n",
    "         #        'LGBM__num_leaves': [500], \n",
    "              #   'LGBM__min_child_samples': [100,150,200,250,300],                                                      \n",
    "              #   'LGBM__reg_alpha' : [1,1.5,2,2.5,3], # default 0 \n",
    "                 'LGBM__min_data_in_leaf' : [50],\n",
    "              #   'LGBM__reg_lambda' : [1,1.5,2,2.5,3], # default 0 \n",
    "              #   'LGBM__subsample_freq' : [1,5,10,100,500], \n",
    "              # 'LGBM__subsample' : [0.5,0.6,0.7,0.8,0.9], \n",
    "               'LGBM__colsample_bytree' : [0.1], \n",
    "            #    'LGBM__min_split_gain' : [50], #\n",
    "},\n",
    "         ]\n",
    "\n",
    "\n",
    "# train/validation with the same ratio of classes\n",
    "kfolds = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(ovsmp_pipe, \n",
    "                    param_grid = param_grid, \n",
    "                    cv = kfolds, \n",
    "                    scoring = 'f1_macro', \n",
    "                    verbose = 2,\n",
    "                    n_jobs = -1)\n",
    "# default lgbm = 0.57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5974bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run the grid search \n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_estimator_,'\\n')\n",
    "print('Best parameters  :', grid.best_params_)\n",
    "print('\\nTraining F1 score:', grid.score(X_train, y_train))\n",
    "print(\"Test F1 score:\", grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d5bee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = grid.predict_proba(X_test)[:,1]\n",
    "scores = print_results('D4_LGBM_oversmp', y_test, grid.predict(X_test), pred_probs)\n",
    "dftmp = pd.DataFrame([scores], columns=score_names)\n",
    "dfAcc = pd.concat([dfAcc, dftmp], ignore_index=True)\n",
    "dfAcc[['TP','FP', 'TN', 'FN']] = dfAcc[['TP','FP', 'TN', 'FN']].astype(int)\n",
    "dfAcc.style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceed5925",
   "metadata": {},
   "source": [
    "# UNDERSAMPLING / LOR¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f997ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsmp_pipe = pipe_imb([('ct'        , ct),\n",
    "                  #     ('dim_red'   , PCA()),\n",
    "                       ('sampler'   , RandomUnderSampler(random_state=42,\n",
    "                                                        sampling_strategy=0.5)),\n",
    "                       ('classifier', LogisticRegression(random_state=42, max_iter=100000))\n",
    "                          ]\n",
    "                   )\n",
    "\n",
    "params = [\n",
    "            {'classifier__C'      :[0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], \n",
    "           'classifier__penalty': ['l1'],\n",
    "           'classifier__solver' : ['liblinear', 'saga'],\n",
    "          #     'dim_red__n_components': [8, 10, 13,15],\n",
    "            'sampler__sampling_strategy': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]},\n",
    "\n",
    "\n",
    "          {'classifier__C'      : [0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], \n",
    "           'classifier__penalty': ['l2'], \n",
    "           'classifier__solver' : ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "          #     'dim_red__n_components': [8, 10, 13,15],\n",
    "            'sampler__sampling_strategy': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "          }]\n",
    "  \n",
    "\n",
    "# train/validation with the same ratio of classes\n",
    "kfold = StratifiedKFold(n_splits = 4, random_state = 42, shuffle=True) \n",
    "\n",
    "grid = GridSearchCV(unsmp_pipe, \n",
    "                    param_grid = params, \n",
    "                    cv = kfold, \n",
    "                    scoring = 'f1_macro', \n",
    "                    verbose = 1,\n",
    "                    n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed49886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run the grid search \n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_estimator_,'\\n')\n",
    "print('Best parameters  :', grid.best_params_)\n",
    "print('\\nTraining F1_macro:', grid.score(X_train, y_train))\n",
    "print('Test F1_macro :', grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529cc8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = grid.predict_proba(X_test)[:,1]\n",
    "scores = print_results('D4_LOR_undersmp', y_test, grid.predict(X_test), pred_probs)\n",
    "dftmp = pd.DataFrame([scores], columns=score_names)\n",
    "dfAcc = pd.concat([dfAcc, dftmp], ignore_index=True)\n",
    "dfAcc[['TP','FP', 'TN', 'FN']] = dfAcc[['TP','FP', 'TN', 'FN']].astype(int)\n",
    "dfAcc.style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd7eca3",
   "metadata": {},
   "source": [
    "# XGB / UNDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcba1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "unsmp_pipe = pipe_imb([('ct'        , ct),\n",
    "                   #     ('dim_red'   , PCA()),\n",
    "                       ('sampler'   , RandomUnderSampler(random_state=42)),\n",
    "                       ('classifier', XGBClassifier(objective='binary:logistic', \n",
    "                                                    eval_metric = f1_macro,\n",
    "                                                    n_estimators=1000, \n",
    "                                                    eta=0.01, # default 0.3\n",
    "                                                    max_depth=6, \n",
    "                                                    subsample=0.8, \n",
    "                                                    min_child_weight=25, \n",
    "                                                    gamma=1, \n",
    "                                                    reg_lambda=1, \n",
    "                                                    alpha=1, \n",
    "                                                    colsample_bytree=0.9, \n",
    "                                                    #colsample_bylevel=0.5,\n",
    "                                                   # scale_pos_weight = 0.35\n",
    "                                                   )\n",
    "                                                   )\n",
    "                            ]\n",
    "                   )\n",
    "\n",
    "\n",
    "params = [{'sampler__sampling_strategy': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "     #     'dim_red__n_components': [8, 10, 13,15],}\n",
    "         ]\n",
    "\n",
    "# train/validation with the same ratio of classes\n",
    "kfold = StratifiedKFold(n_splits = 4, random_state = 42, shuffle=True) \n",
    "\n",
    "grid = GridSearchCV(unsmp_pipe, \n",
    "                    param_grid = params, \n",
    "                    cv = kfold, \n",
    "                    scoring = 'f1_macro', \n",
    "                    verbose = 1,\n",
    "                    n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c070c66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run the grid search \n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_estimator_,'\\n')\n",
    "print('Best parameters  :', grid.best_params_)\n",
    "print('\\nTraining F1_macro:', grid.score(X_train, y_train))\n",
    "print('Test F1_macro :', grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64dd170",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = grid.predict_proba(X_test)[:,1]\n",
    "scores = print_results('D4_XGB_undersmp', y_test, grid.predict(X_test), pred_probs)\n",
    "dftmp = pd.DataFrame([scores], columns=score_names)\n",
    "dfAcc = pd.concat([dfAcc, dftmp], ignore_index=True)\n",
    "dfAcc[['TP','FP', 'TN', 'FN']] = dfAcc[['TP','FP', 'TN', 'FN']].astype(int)\n",
    "dfAcc.style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92a6830",
   "metadata": {},
   "source": [
    "# LGBM / UNDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d636b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsmp_pipe = pipe_imb([('ct'        , ct),\n",
    "                  #     ('dim_red'   , PCA()),\n",
    "                       ('sampler'   , RandomUnderSampler(random_state=42,\n",
    "                                                        sampling_strategy=0.5)),\n",
    "                       ('LGBM',   lgb.LGBMClassifier(objective=\"binary\",\n",
    "                                                   #  class_weight=\"balanced\",                                                   \n",
    "                                                     n_estimators=1000, \n",
    "                                                     learning_rate=0.01,\n",
    "                                                     min_child_weight=25, \n",
    "                                                      max_depth=6, \n",
    "                                                     num_leaves=25, \n",
    "                                                     min_child_samples=25,                                                      \n",
    "                                                     reg_alpha=1, \n",
    "                                                     reg_lambda=1,\n",
    "                                                 #    subsample_freq=0, \n",
    "                                                     colsample_bytree=0.8, \n",
    "                                                     subsample=0.7,\n",
    "                                                     min_split_gain = 25,\n",
    "                                                      min_data_in_leaf = 25,\n",
    "                                                     random_state=42))\n",
    "                          ]\n",
    "                   )\n",
    "\n",
    "param_grid = [{\n",
    "                'sampler__sampling_strategy': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "                #     'dim_red__n_components': [8, 10, 13,15],\n",
    "           #              'LGBM__n_estimators': [750,1000,1500], \n",
    "           #      'LGBM__learning_rate' : [0.0001,0.001,0.01],\n",
    "               #   'LGBM__min_child_weight': [50,100,150], \n",
    "              #    'LGBM__max_depth' : [5], \n",
    "              #   'LGBM__num_leaves': [100,150,200,250,300], \n",
    "              #   'LGBM__min_child_samples': [100,150,200,250,300],                                                      \n",
    "              #   'LGBM__reg_alpha' : [1,1.5,2,2.5,3], # default 0 \n",
    "              #  'LGBM__min_data_in_leaf' : [100,150,200,250,300],\n",
    "              #   'LGBM__reg_lambda' : [1,1.5,2,2.5,3], # default 0 \n",
    "              #   'LGBM__subsample_freq' : [1,5,10,100,500], \n",
    "              # 'LGBM__subsample' : [0.5,0.6,0.7,0.8,0.9], \n",
    "              # 'LGBM__colsample_bytree' : [0.5,0.6,0.7,0.8,0.9], \n",
    "              #  'LGBM__min_split_gain' : [122], \n",
    "              }]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# train/validation with the same ratio of classes\n",
    "kfolds = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(unsmp_pipe, \n",
    "                    param_grid = param_grid, \n",
    "                    cv = kfolds, \n",
    "                    scoring = 'f1_macro', \n",
    "                    verbose = 1,\n",
    "                    n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc76d31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run the grid search \n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_estimator_,'\\n')\n",
    "print('Best parameters  :', grid.best_params_)\n",
    "print('\\nTraining F1_macro:', grid.score(X_train, y_train))\n",
    "print('Test F1_macro :', grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4087062",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = grid.predict_proba(X_test)[:,1]\n",
    "scores = print_results('D4_LGBM_undersmp', y_test, grid.predict(X_test), pred_probs)\n",
    "dftmp = pd.DataFrame([scores], columns=score_names)\n",
    "dfAcc = pd.concat([dfAcc, dftmp], ignore_index=True)\n",
    "dfAcc[['TP','FP', 'TN', 'FN']] = dfAcc[['TP','FP', 'TN', 'FN']].astype(int)\n",
    "dfAcc.style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b70b76",
   "metadata": {},
   "source": [
    "# SMOTE / LOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddd9621",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_pipe = pipe_imb([('ct'        , ct),\n",
    "                 #     ('dim_red'   , PCA()),\n",
    "                       ('sampler'   , SMOTE(random_state=42,\n",
    "                                           sampling_strategy=0.6,\n",
    "                                           k_neighbors=4)),\n",
    "                       ('classifier', LogisticRegression(random_state=42, max_iter=100000))\n",
    "                          ]\n",
    "                   )\n",
    "params = [\n",
    "\n",
    "\n",
    "            {'classifier__C'      :[0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], \n",
    "           'classifier__penalty': ['l1'],\n",
    "           'classifier__solver' : ['liblinear', 'saga'],\n",
    "         #     'dim_red__n_components': [8, 10, 13,15],\n",
    "            'sampler__sampling_strategy': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]},\n",
    "\n",
    "\n",
    "          {'classifier__C'      : [0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], \n",
    "           'classifier__penalty': ['l2'], \n",
    "           'classifier__solver' : ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "        #     'dim_red__n_components': [8, 10, 13,15],\n",
    "            'sampler__sampling_strategy': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "          }]\n",
    "\n",
    "         \n",
    "\n",
    "# train/validation with the same ratio of classes\n",
    "kfold = StratifiedKFold(n_splits = 4, random_state = 42, shuffle=True) \n",
    "\n",
    "grid = GridSearchCV(smote_pipe, \n",
    "                    param_grid = params, \n",
    "                    cv = kfold, \n",
    "                    scoring = 'f1_macro', \n",
    "                    verbose = 1,\n",
    "                    n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d60286",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run the grid search \n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_estimator_,'\\n')\n",
    "print('Best parameters  :', grid.best_params_)\n",
    "print('\\nTraining F1_macro:', grid.score(X_train, y_train))\n",
    "print('Test F1_macro :', grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128cdb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = grid.predict_proba(X_test)[:,1]\n",
    "scores = print_results('D4_LoR_smote', y_test, grid.predict(X_test), pred_probs)\n",
    "dftmp = pd.DataFrame([scores], columns=score_names)\n",
    "dfAcc = pd.concat([dfAcc, dftmp], ignore_index=True)\n",
    "dfAcc[['TP','FP', 'TN', 'FN']] = dfAcc[['TP','FP', 'TN', 'FN']].astype(int)\n",
    "dfAcc.style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d0f75e",
   "metadata": {},
   "source": [
    "# SMOTE / XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d516f6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "smote_pipe = pipe_imb([('ct'        , ct),\n",
    "                  #     ('dim_red'   , PCA()),\n",
    "                       ('sampler'   , SMOTE(random_state=42,\n",
    "                                           sampling_strategy=0.6,\n",
    "                                           k_neighbors=4)),\n",
    "                       ('classifier', XGBClassifier(objective='binary:logistic', \n",
    "                                                    eval_metric = f1_macro,\n",
    "                                                    n_estimators=1000, \n",
    "                                                    eta=0.01, # default 0.3\n",
    "                                                    max_depth=6, \n",
    "                                                    subsample=0.8, \n",
    "                                                    min_child_weight=25, \n",
    "                                                    gamma=1, \n",
    "                                                    reg_lambda=1, \n",
    "                                                    alpha=1, \n",
    "                                                    colsample_bytree=0.9, \n",
    "                                                    #colsample_bylevel=0.5,\n",
    "                                                   # scale_pos_weight = 0.35\n",
    "                                                   )\n",
    "                                                   )\n",
    "                            ]\n",
    "                   )\n",
    "\n",
    "params = {\n",
    "        'sampler__sampling_strategy': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "           \"sampler__k_neighbors\": [3,4,5,6,7,8,9,10],\n",
    "             #     'dim_red__n_components': [8, 10, 13,15],\n",
    "          #  'classifier__n_estimators':[750,1000,1500],\n",
    "          # 'classifier__eta': [0.01,0.001,0.0001]\n",
    "         #   'classifier__max_depth':[5,6],\n",
    "         #  'classifier__min_child_weight': [25]\n",
    "         #  'classifier__colsample_bytree':[0.5,0.6,0.7,0.8,0.9], #0.5\n",
    "         #   'classifier__subsample' : [0.5,0.6,0.7,0.8,0.9],     #0.5\n",
    "         #  'classifier__alpha':[0.2,0.3,0.4], #  defult 0. Increasing this value will make model more conservative.\n",
    "        #    'classifier__gamma':[0.2,0.3,0.4], #  defult 0. Increasing this value will make model more conservative.\n",
    "          #  'classifier__reg_lambda':[0.5,1,1.5,2,2.5], #  def=1 .Increasing this value will make model more conservative.\n",
    "          #  'classifier__scale_pos_weight' : [0.1,0.25,0.3,0.35,1]    #0.35\n",
    "}\n",
    "         \n",
    "\n",
    "# train/validation with the same ratio of classes\n",
    "kfold = StratifiedKFold(n_splits = 4, random_state = 42, shuffle=True) \n",
    "\n",
    "grid = GridSearchCV(smote_pipe, \n",
    "                    param_grid = params, \n",
    "                    cv = kfold, \n",
    "                    scoring = 'f1_macro', \n",
    "                    verbose = 1,\n",
    "                    n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565eeaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run the grid search \n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_estimator_,'\\n')\n",
    "print('Best parameters  :', grid.best_params_)\n",
    "print('\\nTraining F1_macro:', grid.score(X_train, y_train))\n",
    "print('Test F1_macro :', grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f1a6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = grid.predict_proba(X_test)[:,1]\n",
    "scores = print_results('D4_XGB_smote', y_test, grid.predict(X_test), pred_probs)\n",
    "dftmp = pd.DataFrame([scores], columns=score_names)\n",
    "dfAcc = pd.concat([dfAcc, dftmp], ignore_index=True)\n",
    "dfAcc[['TP','FP', 'TN', 'FN']] = dfAcc[['TP','FP', 'TN', 'FN']].astype(int)\n",
    "dfAcc.style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8accf1",
   "metadata": {},
   "source": [
    "# SMOTE / LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bd6267",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_pipe = pipe_imb([('ct'        , ct),\n",
    "                  #     ('dim_red'   , PCA()),\n",
    "                       ('sampler'   , SMOTE(random_state=42,\n",
    "                                           sampling_strategy=0.9,\n",
    "                                           k_neighbors=10)),\n",
    "                       ('LGBM',   lgb.LGBMClassifier(objective=\"binary\",\n",
    "                                                   #  class_weight=\"balanced\",                                                   \n",
    "                                                     n_estimators=1000, \n",
    "                                                     learning_rate=0.01,\n",
    "                                                     min_child_weight=25, \n",
    "                                                      max_depth=6, \n",
    "                                                     num_leaves=25, \n",
    "                                                     min_child_samples=25,                                                      \n",
    "                                                     reg_alpha=1, \n",
    "                                                     reg_lambda=1,\n",
    "                                                 #    subsample_freq=0, \n",
    "                                                     colsample_bytree=0.8, \n",
    "                                                     subsample=0.7,\n",
    "                                                     min_split_gain = 25,\n",
    "                                                      min_data_in_leaf = 25,\n",
    "                                                     random_state=42))\n",
    "                          ]\n",
    "                   )\n",
    "\n",
    "param_grid = {\n",
    "                'sampler__sampling_strategy': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "                'sampler__k_neighbors': [3,4,5,6,7,8,9,10],\n",
    "                #     'dim_red__n_components': [8, 10, 13,15],\n",
    "              #       'LGBM__n_estimators': [750,1000,1500], \n",
    "                 #    'LGBM__learning_rate' : [0.0001,0.001,0.01],\n",
    "                 #     'LGBM__min_child_weight': [100], \n",
    "                  #    'LGBM__max_depth' : [2], \n",
    "                  #   'LGBM__num_leaves': [100,150,200,250,300], \n",
    "                  #   'LGBM__min_child_samples': [100,150,200,250,300],                                                      \n",
    "                  #   'LGBM__reg_alpha' : [1,1.5,2,2.5,3], # default 0 \n",
    "                  #  'LGBM__min_data_in_leaf' : [100,150,200,250,300],\n",
    "                  #   'LGBM__reg_lambda' : [1,1.5,2,2.5,3], # default 0 \n",
    "                  #   'LGBM__subsample_freq' : [1,5,10,100,500], \n",
    "                  # 'LGBM__subsample' : [0.5,0.6,0.7,0.8,0.9], \n",
    "                  # 'LGBM__colsample_bytree' : [0.5,0.6,0.7,0.8,0.9], \n",
    "                  #  'LGBM__min_split_gain' : [122], \n",
    "             }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# train/validation with the same ratio of classes\n",
    "kfolds = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(smote_pipe, \n",
    "                    param_grid = param_grid, \n",
    "                    cv = kfolds, \n",
    "                    scoring = 'f1_macro', \n",
    "                    verbose = 1,\n",
    "                    n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61829c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run the grid search \n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_estimator_,'\\n')\n",
    "print('Best parameters  :', grid.best_params_)\n",
    "print('\\nTraining F1_macro:', grid.score(X_train, y_train))\n",
    "print('Test F1_macro :', grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc747be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = grid.predict_proba(X_test)[:,1]\n",
    "scores = print_results('D4_LGBM_smote', y_test, grid.predict(X_test), pred_probs)\n",
    "dftmp = pd.DataFrame([scores], columns=score_names)\n",
    "dfAcc = pd.concat([dfAcc, dftmp], ignore_index=True)\n",
    "dfAcc[['TP','FP', 'TN', 'FN']] = dfAcc[['TP','FP', 'TN', 'FN']].astype(int)\n",
    "dfAcc.style.hide_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c110df78",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAcc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d6d8bc",
   "metadata": {},
   "source": [
    "# EXPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bcbfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAcc_pck = dfAcc.copy()\n",
    "import pickle \n",
    "fd = open(\"OM_D4_results_table_nx-same-params-tune_only_sampler_params\", 'wb') \n",
    "pickle.dump(dfAcc_pck, fd)\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14ab2e7",
   "metadata": {},
   "source": [
    "# PERMUTATION IMPORTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb4f96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "r = permutation_importance(grid, X_train, y_train,\n",
    "                               n_repeats=30,\n",
    "                             random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d30618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(r.importances);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00232ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.importances_mean # total net amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6afeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[r.importances_mean>0.01]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

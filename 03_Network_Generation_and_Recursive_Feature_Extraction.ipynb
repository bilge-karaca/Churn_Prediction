{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "973864fa",
   "metadata": {},
   "source": [
    "# Customer-Product Network Generation and Recursive Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27230a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle \n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b910b51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('OM_D3_dataset-network_nx', 'rb')\n",
    "data_nx = pickle.load(f)\n",
    "f.close()\n",
    "print(data_nx.shape)\n",
    "\n",
    "f = open('OM_D2_Train_Data_Cleaned', 'rb')\n",
    "df = pickle.load(f)\n",
    "f.close()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0990c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a control column\n",
    "\n",
    "data_nx[\"flag\"] = 0\n",
    "\n",
    "# Expected \"1\" count in the column\n",
    "\n",
    "print(\"Expected 1s:\", data_nx[\"CustomerID\"].isin(df[\"CustomerID\"]).sum())\n",
    "\n",
    "# Take those customers who exist in the train dataset\n",
    "\n",
    "data_nx[\"flag\"] = np.where(data_nx[\"CustomerID\"].isin(df[\"CustomerID\"]), data_nx[\"flag\"].apply(lambda x: 1),0)\n",
    "\n",
    "# Get number of 1s and 0s\n",
    "\n",
    "print(data_nx.flag.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea25f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the flag variable\n",
    "\n",
    "data_nx.drop([\"flag\"],axis=1,inplace=True)\n",
    "print(data_nx.shape)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4b4452",
   "metadata": {},
   "source": [
    "## GRAPH GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe9c14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ca964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_l = []\n",
    "\n",
    "for r in range(len(data_nx)):\n",
    "    edge_l.append((data_nx[\"CustomerID\"][r],(data_nx[\"Ean\"][r])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f29d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create network\n",
    "G.add_edges_from(edge_l)\n",
    "len(G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca36be86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some number cross-checks\n",
    "\n",
    "print(len(data_nx.Ean.unique()) + len(data_nx.CustomerID.unique()))\n",
    "print(len(data_nx.Ean.unique()), len(data_nx.CustomerID.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dd3e1a",
   "metadata": {},
   "source": [
    "## FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b1306f",
   "metadata": {},
   "source": [
    "### generate RolX Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a61d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphrole import RecursiveFeatureExtractor, RoleExtractor\n",
    "from node2vec import Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff3b943",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "feat_ext = RecursiveFeatureExtractor(G, max_generations=4)\n",
    "rolx_feats = feat_ext.extract_features()\n",
    "\n",
    "print(f'\\nFeatures extracted from {feat_ext.generation_count} recursive generations:')\n",
    "print(rolx_feats.shape, rolx_feats.columns)\n",
    "\n",
    "df_feats_all = rolx_feats.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264cd8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feats_all_pck = df_feats_all.copy()\n",
    "import pickle \n",
    "f = open(\"OM_nx_rolx_features\", 'wb') \n",
    "pickle.dump(df_feats_all_pck, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f3ad48",
   "metadata": {},
   "source": [
    "## Merge train_data with extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4180716",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbe2c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feats_all.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd16e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feats_all.reset_index(drop=False,inplace=True) \n",
    "df_feats_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fa49ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feats_all.rename(columns={\"index\": \"CustomerID\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e8b40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nx = df.merge(df_feats_all, on=\"CustomerID\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b46e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some number cross-checks\n",
    "print(df.shape)\n",
    "print(df_feats_all.shape)\n",
    "print(data_nx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f915e5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_nx_pck = data_nx.copy()\n",
    "import pickle \n",
    "f = open(\"OM_D3_Dataset_2_nx-features\", 'wb') \n",
    "pickle.dump(dataset_nx_pck, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99065222",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facb40ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, precision_recall_curve\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, roc_auc_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e19b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame to store the results\n",
    "def print_results(headline, true_value, pred, probs):\n",
    "    scores=[]\n",
    "    CM = confusion_matrix(true_value, pred)\n",
    "    scores.append(headline)\n",
    "    scores.append(accuracy_score(true_value, pred))      #accuracy\n",
    "    scores.append(int(CM[1,1]))                          #TP\n",
    "    scores.append(int(CM[0,1]))                          #FP\n",
    "    scores.append(int(CM[0][0]))                         #TN\n",
    "    scores.append(int(CM[1][0]))                         #FN\n",
    "    scores.append(precision_score(true_value, pred))     #precision\n",
    "    scores.append(recall_score(true_value, pred))        #recall\n",
    "    scores.append(roc_auc_score(true_value, probs))      #roc_auc\n",
    "    p, r, _ = precision_recall_curve(true_value, probs) \n",
    "    scores.append(auc(r,p))                              #pr_auc\n",
    "    scores.append(f1_score(true_value, pred, average=\"macro\"))            #f1-score\n",
    "    return scores\n",
    "\n",
    "score_names = ['method','accuracy','TP','FP','TN','FN','precision','recall','roc_auc','pr_auc','f1']\n",
    "dfAcc = pd.DataFrame(data=np.zeros(shape=(0,11)), columns = score_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ccd088",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= data_nx.drop([\"CustomerID\",\"label\"],axis=1)\n",
    "y= data_nx[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b36cef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars= ['isContactable','City', 'last_coupon_type_used','Device']\n",
    "X.drop(cat_vars,axis=1,inplace=True)\n",
    "num_vars=list(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a3ff5f",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251ec69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "num_vars = list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db853c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"pipe_cat = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"one_hot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\"\"\"\n",
    "pipe_num = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    #(\"categorical_vars\", pipe_cat, cat_vars),\n",
    "    (\"numeric_vars\", pipe_num, num_vars),\n",
    "    \n",
    "], remainder=\"passthrough\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b9005e",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef7d934",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('ct', ct),\n",
    "                       ('classifier', LogisticRegression(random_state=42, max_iter=100000))\n",
    "                          ]\n",
    "                   )\n",
    "\n",
    "params = [\n",
    "\n",
    "            {'classifier__C'      : [0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], \n",
    "           'classifier__penalty': ['l1'],\n",
    "           'classifier__solver' : ['liblinear', 'saga']},\n",
    "\n",
    "\n",
    "          {'classifier__C'      : [0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], \n",
    "           'classifier__penalty': ['l2'], \n",
    "           'classifier__solver' : ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "          }]\n",
    "\n",
    "         \n",
    "\n",
    "# train/validation with the same ratio of classes\n",
    "kfold = StratifiedKFold(n_splits = 4, random_state = 42, shuffle=True) \n",
    "\n",
    "grid = GridSearchCV(pipe, \n",
    "                    param_grid = params, \n",
    "                    cv = kfold, \n",
    "                    scoring = 'f1_macro', \n",
    "                    verbose = 1,\n",
    "                    n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89dd4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run the grid search \n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_estimator_,'\\n')\n",
    "print('Best parameters  :', grid.best_params_)\n",
    "print('\\nTraining F1_macro:', grid.score(X_train, y_train))\n",
    "print('Test F1_macro :', grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76999c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = grid.predict_proba(X_test)[:,1]\n",
    "scores = print_results('D3_LoR_sp', y_test, grid.predict(X_test), pred_probs)\n",
    "dftmp = pd.DataFrame([scores], columns=score_names)\n",
    "dfAcc = pd.concat([dfAcc, dftmp], ignore_index=True)\n",
    "dfAcc[['TP','FP', 'TN', 'FN']] = dfAcc[['TP','FP', 'TN', 'FN']].astype(int)\n",
    "dfAcc.style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe74cfb",
   "metadata": {},
   "source": [
    "# D3_XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da33e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_macro(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a705a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "pipe = Pipeline(steps=[('ct', ct),\n",
    "                       ('classifier', XGBClassifier(objective='binary:logistic', \n",
    "                                                    eval_metric = f1_macro,\n",
    "                                                    n_estimators=1000, \n",
    "                                                    eta=0.01, # default 0.3\n",
    "                                                    max_depth=8, \n",
    "                                                    subsample=0.7, \n",
    "                                                    min_child_weight=55, \n",
    "                                                    gamma=1, \n",
    "                                                    reg_lambda=1, \n",
    "                                                    alpha=1, \n",
    "                                                    colsample_bytree=0.9, \n",
    "                                                    #colsample_bylevel=0.5,\n",
    "                                                   # scale_pos_weight = 0.35\n",
    "                                                   )\n",
    "                                                   )\n",
    "                            ]\n",
    "                   )\n",
    "\n",
    "params = [{ \n",
    "            #'classifier__n_estimators':[750,1000,1500],\n",
    "           #'classifier__eta': [0.01],\n",
    "           # 'classifier__max_depth':[8,9,10],\n",
    "          # 'classifier__min_child_weight': [50,55,60],\n",
    "         #  'classifier__colsample_bytree':[0.7,0.8,0.9],\n",
    "           # 'classifier__subsample' : [0.6,0.7,0.8],\n",
    "         #  'classifier__alpha':[0.2,0.3,0.4], #  defult 0. Increasing this value will make model more conservative.\n",
    "        #    'classifier__gamma':[0.2,0.3,0.4], #  defult 0. Increasing this value will make model more conservative.\n",
    "          #  'classifier__reg_lambda':[0.5,1,1.5,2,2.5], #  def=1 .Increasing this value will make model more conservative.\n",
    "          #  'classifier__scale_pos_weight' : [0.25,0.3,0.35]\n",
    "          }\n",
    "         ]\n",
    "\n",
    "# train/validation with the same ratio of classes\n",
    "kfold = StratifiedKFold(n_splits = 4, random_state = 42, shuffle=True) \n",
    "\n",
    "grid = GridSearchCV(pipe, \n",
    "                    param_grid = params, \n",
    "                    cv = kfold, \n",
    "                    scoring = 'f1_macro', \n",
    "                    verbose = 1,\n",
    "                    n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bc0beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run the grid search \n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_estimator_,'\\n')\n",
    "print('Best parameters  :', grid.best_params_)\n",
    "print('\\nTraining F1 score:', grid.score(X_train, y_train))\n",
    "print(\"Test F1 score:\", grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2d7b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = grid.predict_proba(X_test)[:,1]\n",
    "scores = print_results('D3_XGB_sp', y_test, grid.predict(X_test), pred_probs)\n",
    "dftmp = pd.DataFrame([scores], columns=score_names)\n",
    "dfAcc = pd.concat([dfAcc, dftmp], ignore_index=True)\n",
    "dfAcc[['TP','FP', 'TN', 'FN']] = dfAcc[['TP','FP', 'TN', 'FN']].astype(int)\n",
    "dfAcc.style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5cde34",
   "metadata": {},
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ecb3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SGD\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "pipe = Pipeline(steps=[('ct', ct), \n",
    "                       ('SGD', SGDClassifier(random_state = 42,\n",
    "                                             class_weight=\"balanced\", \n",
    "                                             warm_start=False, \n",
    "                                             average=False,\n",
    "                                             loss= \"log_loss\",\n",
    "                                           #  learning_rate=\"adaptive\",\n",
    "                                             alpha = 0.05,\n",
    "                                             eta0 = 0.1,\n",
    "                                             learning_rate=\"adaptive\",\n",
    "                                             penalty=\"l1\"\n",
    "                                             \n",
    "                                            )\n",
    "                                            )\n",
    "                          ]\n",
    "                   )\n",
    "\n",
    "param_grid = {#\"SGD__alpha\":[0.01,0.03,0.05], # The higher the value, the stronger the regularization.\n",
    "              #\"SGD__penalty\": [\"l1\",\"l2\", \"elasticnet\"],\n",
    "              #\"SGD__class_weight\": [\"balanced\", 0.5,0.7,1,1.5],\n",
    "              #\"SGD__learning_rate\" : [\"constant\", \"optimal\", \"invscaling\", \"adaptive\"],\n",
    "              #\"SGD__eta0\" : [0.0001,0.001,0.01,0.1]\n",
    "             } \n",
    "\n",
    "\n",
    "# train/validation with the same ratio of classes\n",
    "kfolds = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(pipe, \n",
    "                    param_grid = param_grid, \n",
    "                    cv = kfolds, \n",
    "                    scoring = 'f1_macro', \n",
    "                    verbose = 1,\n",
    "                    n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5807603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run the grid search \n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_estimator_,'\\n')\n",
    "print('Best parameters  :', grid.best_params_)\n",
    "print('\\nTraining F1 score:', grid.score(X_train, y_train))\n",
    "print(\"Test F1 score:\", grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd402bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = grid.predict_proba(X_test)[:,1]\n",
    "scores = print_results('D2_SGD_nt', y_test, grid.predict(X_test), pred_probs)\n",
    "dftmp = pd.DataFrame([scores], columns=score_names)\n",
    "dfAcc = pd.concat([dfAcc, dftmp], ignore_index=True)\n",
    "dfAcc[['TP','FP', 'TN', 'FN']] = dfAcc[['TP','FP', 'TN', 'FN']].astype(int)\n",
    "dfAcc.style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d423a62f",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e383e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipe = Pipeline(steps=[('ct', ct),\n",
    "                        ('RF', RandomForestClassifier(random_state = 42, \n",
    "                                                       n_estimators=1000,\n",
    "                                                      criterion=\"gini\", \n",
    "                                                       max_depth=7, \n",
    "                                                       min_samples_split = 30,\n",
    "                                                       max_features='sqrt', \n",
    "                                                     #  min_samples_leaf=10,\n",
    "                                                       class_weight = \"balanced\"\n",
    "                                                     ))\n",
    "                      ]\n",
    "                   )\n",
    "\n",
    "param_grid = { #\"RF__n_estimators\": [750,1000,1500],\n",
    "               # \"RF__max_depth\": [5,6,7],\n",
    "              #  \"RF__min_samples_split\": [45],\n",
    "               # \"RF__max_features\": [\"sqrt\", \"log2\", 10],\n",
    "             # \"RF__criterion\"   : [\"gini\",\"entropy\",\"log_loss\"],\n",
    "                                      } \n",
    "\n",
    "\n",
    "# train/validation with the same ratio of classes\n",
    "kfolds = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(pipe, \n",
    "                    param_grid = param_grid, \n",
    "                    cv = kfolds, \n",
    "                    scoring = 'f1_macro', \n",
    "                    verbose = 1,\n",
    "                    n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87455bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run the grid search \n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_estimator_,'\\n')\n",
    "print('Best parameters  :', grid.best_params_)\n",
    "print('\\nTraining F1 score:', grid.score(X_train, y_train))\n",
    "print(\"Test F1 score:\", grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b31ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = grid.predict_proba(X_test)[:,1]\n",
    "scores = print_results('D3_RF_sp', y_test, grid.predict(X_test), pred_probs)\n",
    "dftmp = pd.DataFrame([scores], columns=score_names)\n",
    "dfAcc = pd.concat([dfAcc, dftmp], ignore_index=True)\n",
    "dfAcc[['TP','FP', 'TN', 'FN']] = dfAcc[['TP','FP', 'TN', 'FN']].astype(int)\n",
    "dfAcc.style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25456618",
   "metadata": {},
   "source": [
    "# LIGHTGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbe73a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIGHTGBM\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "pipe = Pipeline(steps=[('ct', ct), \n",
    "                       ('LGBM',   lgb.LGBMClassifier(objective=\"binary\",\n",
    "                                                #     class_weight=\"balanced\",                                                   \n",
    "                                                     n_estimators=1500, \n",
    "                                                     learning_rate=0.01,\n",
    "                                                     min_child_weight=25, \n",
    "                                                     max_depth=7, \n",
    "                                                     num_leaves=25, \n",
    "                                                     min_child_samples=50,                                                      \n",
    "                                                     reg_alpha=0.8, \n",
    "                                                     reg_lambda=0.8,\n",
    "                                                 #    subsample_freq=0, \n",
    "                                                     colsample_bytree=0.9, \n",
    "                                                     subsample=0.8,\n",
    "                                                     min_split_gain = 25,\n",
    "                                                     min_data_in_leaf = 25,\n",
    "                                                     random_state=42))\n",
    "                          ]\n",
    "                   )\n",
    "\n",
    "param_grid = {\n",
    "              #   'LGBM__n_estimators': [750,1000,1500], \n",
    "              #   'LGBM__learning_rate' : [0.0001,0.001,0.01],\n",
    "              #    'LGBM__min_child_weight': [250], \n",
    "              #    'LGBM__max_depth' : [5], \n",
    "               #  'LGBM__num_leaves': [250], \n",
    "              #   'LGBM__min_child_samples': [100,150,200,250,300],                                                      \n",
    "              #   'LGBM__reg_alpha' : [5,6,7], # default 0 \n",
    "              #  'LGBM__min_data_in_leaf' : [100,150,200,250,300],\n",
    "              #   'LGBM__reg_lambda' : [1,1.5,2,2.5,3], # default 0 \n",
    "              #   'LGBM__subsample_freq' : [1,5,10,100,500], \n",
    "             #  'LGBM__subsample' : [0.5,0.6,0.7,0.8,0.9], \n",
    "              # 'LGBM__colsample_bytree' : [0.5,0.6,0.7,0.8,0.9], \n",
    "              #  'LGBM__min_split_gain' : [122], \n",
    "             } \n",
    "\n",
    "\n",
    "# train/validation with the same ratio of classes\n",
    "kfolds = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(pipe, \n",
    "                    param_grid = param_grid, \n",
    "                    cv = kfolds, \n",
    "                    scoring = 'f1_macro', \n",
    "                    verbose = 2,\n",
    "                    n_jobs = -1)\n",
    "# default lgbm = 0.57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5974bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run the grid search \n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_estimator_,'\\n')\n",
    "print('Best parameters  :', grid.best_params_)\n",
    "print('\\nTraining F1 score:', grid.score(X_train, y_train))\n",
    "print(\"Test F1 score:\", grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d5bee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = grid.predict_proba(X_test)[:,1]\n",
    "scores = print_results('D3_LGBM_sp', y_test, grid.predict(X_test), pred_probs)\n",
    "dftmp = pd.DataFrame([scores], columns=score_names)\n",
    "dfAcc = pd.concat([dfAcc, dftmp], ignore_index=True)\n",
    "dfAcc[['TP','FP', 'TN', 'FN']] = dfAcc[['TP','FP', 'TN', 'FN']].astype(int)\n",
    "dfAcc.style.hide_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bcbfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAcc_pck = dfAcc.copy()\n",
    "import pickle \n",
    "fd = open(\"OM_D3_results_table\", 'wb') \n",
    "pickle.dump(dfAcc_pck, fd)\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05234aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_nx_pck = data_nx.copy()\n",
    "import pickle \n",
    "f = open(\"NF_D3_Dataset_2_nx-features-added\", 'wb') \n",
    "pickle.dump(dataset_nx_pck, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14ab2e7",
   "metadata": {},
   "source": [
    "# PERMUTATION IMPORTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb4f96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "r = permutation_importance(grid, X_train, y_train,\n",
    "                               n_repeats=30,\n",
    "                             random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d30618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(r.importances);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00232ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.importances_mean #Â total net amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6afeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[r.importances_mean>0.01]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
